{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAGE III - REAL WORLD OPTIMIZATION\n",
    "\n",
    "![FIGURE](STAGE-III.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMON\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Triggering Mechanism\n",
    "import triggering as trig\n",
    "\n",
    "# Signal Processing\n",
    "from scipy import signal  # for signal processing\n",
    "from scipy.signal import hilbert  # for signal processing\n",
    "import prenn # for deep learning\n",
    "\n",
    "# AI\n",
    "import keras\n",
    "\n",
    "import tensorflow as tf # for deep learning\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.callbacks import TensorBoard # for visualization\n",
    "\n",
    "import onnxruntime as ort # for onnx runtime\n",
    "\n",
    "# Visualization\n",
    "# %matplotlib qt5\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.animation import FuncAnimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLOSED-LOOP CONTROL COMPONENTS SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENVIRONMENT\n",
    "\n",
    "IN NATURE - THE SYNTHESIZED RESPONSE DATA - DIFFERENT FROM STAGE II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "RESPONSE_AV Shape: (150, 6000)\n",
      "<class 'numpy.ndarray'>\n",
      "RESPONSE_EQ Shape: (50, 6000)\n",
      "<class 'numpy.ndarray'>\n",
      "RESPONSE_IP Shape: (50, 6000)\n",
      "<class 'numpy.ndarray'>\n",
      "RESPONSE_SW Shape: (50, 6000)\n",
      "Ratio of Non-Interested Data to Interested Data: 1.0\n",
      "Total Number of Samples: 300\n"
     ]
    }
   ],
   "source": [
    "# Corrected Paths\n",
    "AVPath = r'../01-PRE-DEPLOYMENT/DATA/VAL_RES/VAL_DATA_AV.npy' \n",
    "EQPath = r'../01-PRE-DEPLOYMENT/DATA/VAL_RES/VAL_DATA_EQ.npy'\n",
    "IPPath = r'../01-PRE-DEPLOYMENT/DATA/VAL_RES/VAL_DATA_IP.npy'\n",
    "SWPath = r'../01-PRE-DEPLOYMENT/DATA/VAL_RES/VAL_DATA_SW.npy'\n",
    "\n",
    "# Load Data\n",
    "RESPONSE_AV = np.load(AVPath)\n",
    "RESPONSE_EQ = np.load(EQPath)\n",
    "RESPONSE_IP = np.load(IPPath)\n",
    "RESPONSE_SW = np.load(SWPath)\n",
    "\n",
    "## only use part of the data\n",
    "raw_len_av = RESPONSE_AV.shape[0]\n",
    "raw_len_eq = RESPONSE_EQ.shape[0]\n",
    "raw_len_ip = RESPONSE_IP.shape[0]\n",
    "raw_len_sw = RESPONSE_SW.shape[0]\n",
    "\n",
    "# this is to simulate the imbalanced data - ensure the same ratio within STAGE III\n",
    "ratio_aw = 0.6\n",
    "ratio_eq = 1\n",
    "ratio_ip = 1\n",
    "ratio_sw = 1\n",
    "\n",
    "uselen_aw = int(raw_len_av * ratio_aw)\n",
    "uselen_eq = int(raw_len_eq * ratio_eq)  \n",
    "uselen_ip = int(raw_len_ip * ratio_ip)\n",
    "uselen_sw = int(raw_len_sw * ratio_sw)\n",
    "\n",
    "# randomly pick uselen_aw samples from RESPONSE_XX, no repeat\n",
    "idx_aw = random.sample(range(raw_len_av), uselen_aw)\n",
    "idx_eq = random.sample(range(raw_len_eq), uselen_eq)\n",
    "idx_ip = random.sample(range(raw_len_ip), uselen_ip)\n",
    "idx_sw = random.sample(range(raw_len_sw), uselen_sw)\n",
    "\n",
    "RESPONSE_AV = RESPONSE_AV[idx_aw]\n",
    "RESPONSE_EQ = RESPONSE_EQ[idx_eq]\n",
    "RESPONSE_IP = RESPONSE_IP[idx_ip]\n",
    "RESPONSE_SW = RESPONSE_SW[idx_sw]\n",
    "\n",
    "## Check Data Info\n",
    "print(type(RESPONSE_AV))\n",
    "print('RESPONSE_AV Shape:', RESPONSE_AV.shape)\n",
    "print(type(RESPONSE_EQ))\n",
    "print('RESPONSE_EQ Shape:', RESPONSE_EQ.shape)\n",
    "print(type(RESPONSE_IP))\n",
    "print('RESPONSE_IP Shape:', RESPONSE_IP.shape)\n",
    "print(type(RESPONSE_SW))\n",
    "print('RESPONSE_SW Shape:', RESPONSE_SW.shape)\n",
    "\n",
    "num_type = 4\n",
    "\n",
    "signal_length = RESPONSE_AV.shape[1]\n",
    "\n",
    "LenTS = signal_length\n",
    "\n",
    "# ratio of non-interested data to interested data\n",
    "ratio_ni = RESPONSE_AV.shape[0] / (RESPONSE_EQ.shape[0] + RESPONSE_IP.shape[0] + RESPONSE_SW.shape[0])\n",
    "\n",
    "print('Ratio of Non-Interested Data to Interested Data:', ratio_ni)\n",
    "\n",
    "## Stack Data\n",
    "RESPONSE = np.vstack((RESPONSE_AV, RESPONSE_EQ, RESPONSE_IP, RESPONSE_SW))\n",
    "\n",
    "## Total Number of Samples\n",
    "NumSample = RESPONSE.shape[0]\n",
    "print('Total Number of Samples:', NumSample) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of AV: 150\n",
      "Number of EQ: 50\n",
      "Number of IP: 50\n",
      "Number of SW: 50\n"
     ]
    }
   ],
   "source": [
    "NUM_AV = RESPONSE_AV.shape[0]\n",
    "NUM_EQ = RESPONSE_EQ.shape[0]\n",
    "NUM_IP = RESPONSE_IP.shape[0]\n",
    "NUM_SW = RESPONSE_SW.shape[0]\n",
    "\n",
    "#print\n",
    "print('Number of AV:', NUM_AV)\n",
    "print('Number of EQ:', NUM_EQ)\n",
    "print('Number of IP:', NUM_IP)\n",
    "print('Number of SW:', NUM_SW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SYSTEM\n",
    "IN NATURE - THE TRIGGERING MECHANISM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embodied in the triggering.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum of AV: 0.0168420367172138\n",
      "Minimum of AV: 5.263614397604116e-06\n"
     ]
    }
   ],
   "source": [
    "# determine the search space by check the maximum and minimum of the data - ambient vibration\n",
    "max_noise = np.max(abs(RESPONSE_AV))\n",
    "min_noise = np.min(abs(RESPONSE_AV))\n",
    "print('Maximum of AV:', max_noise)\n",
    "print('Minimum of AV:', min_noise)\n",
    "\n",
    "# determine the lower and upper bound of the search space\n",
    "ub_factor = 2\n",
    "lb_factor = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower Bound of para_a: 8.423650165805703e-05\n",
      "Upper Bound of para_a: 0.016847300331611404\n",
      "Lower Bound of para_b: 2\n",
      "Upper Bound of para_b: 10\n"
     ]
    }
   ],
   "source": [
    "# configuration\n",
    "\n",
    "## para_a stands for the triggering threshold amplitude (continuous)\n",
    "para_a_lb = lb_factor*(max_noise + min_noise)/2\n",
    "para_a_ub = ub_factor*(max_noise + min_noise)/2\n",
    "\n",
    "print('Lower Bound of para_a:', para_a_lb)\n",
    "print('Upper Bound of para_a:', para_a_ub)\n",
    "\n",
    "## para_b stands for the triggering threshold duration (discrete integer)\n",
    "para_b_lb = 2\n",
    "para_b_ub = 10\n",
    "\n",
    "print('Lower Bound of para_b:', para_b_lb)\n",
    "print('Upper Bound of para_b:', para_b_ub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "test_data = RESPONSE_AV[0]\n",
    "\n",
    "para_a = 0.5\n",
    "para_b = 2\n",
    "\n",
    "trig_flg = trig.activation(test_data, para_a, para_b)\n",
    "print(trig_flg[0]) # the first element stands for the triggering flag, and the second element stands for the triggering time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESTIMATOR\n",
    "IN NATURE - TRIGGERING MECHANISM & GROUND TRUTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 1.75 # beta value to balance the precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USED PARAMETER of the Dataset\n",
    "\n",
    "# nn_in_len = 128 # nn input length can be automatically calculated from the model input size\n",
    "dt = 0.01  # time step, change according to the dataset\n",
    "nperseg = 128 # number of points for each segment in spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier - CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not deserialize class 'Functional' because its parent module keras.src.models.functional cannot be imported. Full object config: {'module': 'keras.src.models.functional', 'class_name': 'Functional', 'config': {'name': 'functional', 'trainable': True, 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': [None, 128, 1], 'dtype': 'float32', 'sparse': False, 'name': 'input_layer'}, 'registered_name': None, 'name': 'input_layer', 'inbound_nodes': []}, {'module': 'keras.layers', 'class_name': 'Conv1D', 'config': {'name': 'conv1d', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'filters': 4, 'kernel_size': [3], 'strides': [1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 128, 1]}, 'name': 'conv1d', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 1], 'dtype': 'float32', 'keras_history': ['input_layer', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None, 'synchronized': False}, 'registered_name': None, 'build_config': {'input_shape': [None, 128, 4]}, 'name': 'batch_normalization', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 4], 'dtype': 'float32', 'keras_history': ['conv1d', 0, 0]}}], 'kwargs': {'mask': None}}]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'name': 're_lu', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 4], 'dtype': 'float32', 'keras_history': ['batch_normalization', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'GlobalAveragePooling1D', 'config': {'name': 'global_average_pooling1d', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'data_format': 'channels_last', 'keepdims': False}, 'registered_name': None, 'name': 'global_average_pooling1d', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 4], 'dtype': 'float32', 'keras_history': ['re_lu', 0, 0]}}], 'kwargs': {'mask': None}}]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'units': 4, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 4]}, 'name': 'dense', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 4], 'dtype': 'float32', 'keras_history': ['global_average_pooling1d', 0, 0]}}], 'kwargs': {}}]}], 'input_layers': [['input_layer', 0, 0]], 'output_layers': [['dense', 0, 0]]}, 'registered_name': 'Functional', 'build_config': {'input_shape': None}, 'compile_config': {'optimizer': {'module': 'keras.optimizers', 'class_name': 'Adam', 'config': {'name': 'adam', 'learning_rate': 0.0010000000474974513, 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'loss_scale_factor': None, 'gradient_accumulation_steps': None, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}, 'registered_name': None}, 'loss': 'sparse_categorical_crossentropy', 'loss_weights': None, 'metrics': ['sparse_categorical_accuracy'], 'weighted_metrics': None, 'run_eagerly': False, 'steps_per_execution': 1, 'jit_compile': False}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:800\u001b[0m, in \u001b[0;36m_retrieve_class_or_fn\u001b[0;34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 800\u001b[0m     mod \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(module)\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.src.models.functional'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# CNN Classifier Model Path\u001b[39;00m\n\u001b[1;32m      2\u001b[0m classifier_model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../01-PRE-DEPLOYMENT/03-NN-TRAINING-CNN/cnn_model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m CNN_Model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39msaving\u001b[38;5;241m.\u001b[39mload_model(classifier_model_path)\n\u001b[1;32m      4\u001b[0m CNN_Model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/saving/saving_api.py:254\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    251\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following argument(s) are not supported \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    252\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith the native Keras format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    253\u001b[0m         )\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    255\u001b[0m         filepath,\n\u001b[1;32m    256\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[1;32m    258\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    263\u001b[0m     filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    264\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:281\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    278\u001b[0m             asset_store\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:246\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ObjectSharingScope():\n\u001b[0;32m--> 246\u001b[0m     model \u001b[38;5;241m=\u001b[39m deserialize_keras_object(\n\u001b[1;32m    247\u001b[0m         config_dict, custom_objects, safe_mode\u001b[38;5;241m=\u001b[39msafe_mode\n\u001b[1;32m    248\u001b[0m     )\n\u001b[1;32m    250\u001b[0m all_filenames \u001b[38;5;241m=\u001b[39m zf\u001b[38;5;241m.\u001b[39mnamelist()\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _VARS_FNAME \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m all_filenames:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:705\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m--> 705\u001b[0m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m _retrieve_class_or_fn(\n\u001b[1;32m    706\u001b[0m     class_name,\n\u001b[1;32m    707\u001b[0m     registered_name,\n\u001b[1;32m    708\u001b[0m     module,\n\u001b[1;32m    709\u001b[0m     obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    710\u001b[0m     full_config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    711\u001b[0m     custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    712\u001b[0m )\n\u001b[1;32m    714\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mcls\u001b[39m, types\u001b[38;5;241m.\u001b[39mFunctionType):\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.11/site-packages/keras/src/saving/serialization_lib.py:802\u001b[0m, in \u001b[0;36m_retrieve_class_or_fn\u001b[0;34m(name, registered_name, module, obj_type, full_config, custom_objects)\u001b[0m\n\u001b[1;32m    800\u001b[0m     mod \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(module)\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[0;32m--> 802\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    803\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not deserialize \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m because \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    804\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mits parent module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be imported. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    805\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull object config: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_config\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    806\u001b[0m     )\n\u001b[1;32m    807\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mvars\u001b[39m(mod)\u001b[38;5;241m.\u001b[39mget(name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;66;03m# Special case for keras.metrics.metrics\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not deserialize class 'Functional' because its parent module keras.src.models.functional cannot be imported. Full object config: {'module': 'keras.src.models.functional', 'class_name': 'Functional', 'config': {'name': 'functional', 'trainable': True, 'layers': [{'module': 'keras.layers', 'class_name': 'InputLayer', 'config': {'batch_shape': [None, 128, 1], 'dtype': 'float32', 'sparse': False, 'name': 'input_layer'}, 'registered_name': None, 'name': 'input_layer', 'inbound_nodes': []}, {'module': 'keras.layers', 'class_name': 'Conv1D', 'config': {'name': 'conv1d', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'filters': 4, 'kernel_size': [3], 'strides': [1], 'padding': 'same', 'data_format': 'channels_last', 'dilation_rate': [1], 'groups': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 128, 1]}, 'name': 'conv1d', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 1], 'dtype': 'float32', 'keras_history': ['input_layer', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'gamma_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'moving_mean_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'moving_variance_initializer': {'module': 'keras.initializers', 'class_name': 'Ones', 'config': {}, 'registered_name': None}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None, 'synchronized': False}, 'registered_name': None, 'build_config': {'input_shape': [None, 128, 4]}, 'name': 'batch_normalization', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 4], 'dtype': 'float32', 'keras_history': ['conv1d', 0, 0]}}], 'kwargs': {'mask': None}}]}, {'module': 'keras.layers', 'class_name': 'ReLU', 'config': {'name': 're_lu', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'max_value': None, 'negative_slope': 0.0, 'threshold': 0.0}, 'registered_name': None, 'name': 're_lu', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 4], 'dtype': 'float32', 'keras_history': ['batch_normalization', 0, 0]}}], 'kwargs': {}}]}, {'module': 'keras.layers', 'class_name': 'GlobalAveragePooling1D', 'config': {'name': 'global_average_pooling1d', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'data_format': 'channels_last', 'keepdims': False}, 'registered_name': None, 'name': 'global_average_pooling1d', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 128, 4], 'dtype': 'float32', 'keras_history': ['re_lu', 0, 0]}}], 'kwargs': {'mask': None}}]}, {'module': 'keras.layers', 'class_name': 'Dense', 'config': {'name': 'dense', 'trainable': True, 'dtype': {'module': 'keras', 'class_name': 'DTypePolicy', 'config': {'name': 'float32'}, 'registered_name': None}, 'units': 4, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'module': 'keras.initializers', 'class_name': 'GlorotUniform', 'config': {'seed': None}, 'registered_name': None}, 'bias_initializer': {'module': 'keras.initializers', 'class_name': 'Zeros', 'config': {}, 'registered_name': None}, 'kernel_regularizer': None, 'bias_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'registered_name': None, 'build_config': {'input_shape': [None, 4]}, 'name': 'dense', 'inbound_nodes': [{'args': [{'class_name': '__keras_tensor__', 'config': {'shape': [None, 4], 'dtype': 'float32', 'keras_history': ['global_average_pooling1d', 0, 0]}}], 'kwargs': {}}]}], 'input_layers': [['input_layer', 0, 0]], 'output_layers': [['dense', 0, 0]]}, 'registered_name': 'Functional', 'build_config': {'input_shape': None}, 'compile_config': {'optimizer': {'module': 'keras.optimizers', 'class_name': 'Adam', 'config': {'name': 'adam', 'learning_rate': 0.0010000000474974513, 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'loss_scale_factor': None, 'gradient_accumulation_steps': None, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}, 'registered_name': None}, 'loss': 'sparse_categorical_crossentropy', 'loss_weights': None, 'metrics': ['sparse_categorical_accuracy'], 'weighted_metrics': None, 'run_eagerly': False, 'steps_per_execution': 1, 'jit_compile': False}}"
     ]
    }
   ],
   "source": [
    "# CNN Classifier Model Path\n",
    "classifier_model_path = r'../01-PRE-DEPLOYMENT/03-NN-TRAINING-CNN/cnn_model.keras'\n",
    "CNN_Model = keras.saving.load_model(classifier_model_path)\n",
    "CNN_Model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictor - DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN Predictor Model Path\n",
    "recall_model_path = r'../01-PRE-DEPLOYMENT/04-NN-TRAINING-DNN/recall_est.keras'\n",
    "Recall_Model = keras.saving.load_model(recall_model_path)\n",
    "Recall_Model.summary()\n",
    "\n",
    "# DNN Predictor Model Path\n",
    "precision_model_path = r'../01-PRE-DEPLOYMENT/04-NN-TRAINING-DNN/precision_est.keras'\n",
    "Precision_Model = keras.saving.load_model(precision_model_path)\n",
    "Precision_Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the input data length\n",
    "nn_in_len = CNN_Model.input_shape[1]\n",
    "print('Input Data Length:', nn_in_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model test by loading a piece of data from the dataset, and feed intot he prenn function\n",
    "\n",
    "# index for the random data\n",
    "idx = np.random.randint(NumSample)\n",
    "\n",
    "# get the data\n",
    "test_data = RESPONSE[idx, :].reshape(1, LenTS)\n",
    "\n",
    "print('Test Data Shape:', test_data.shape)\n",
    "\n",
    "# plot the test data\n",
    "plt.figure()\n",
    "plt.plot(test_data[0, :])\n",
    "plt.title('Test Data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "output_length = nn_in_len\n",
    "test_data = prenn.prenn(test_data, dt, nperseg, output_length)\n",
    "\n",
    "# print the preprocessed data\n",
    "plt.figure()\n",
    "plt.plot(test_data[0, :])\n",
    "plt.title('Preprocessed Test Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.reshape(1, nn_in_len, 1)\n",
    "\n",
    "print('Preprocessed Test Data Shape:', test_data.shape)\n",
    "\n",
    "# test the model\n",
    "test_result = CNN_Model.predict(test_data)\n",
    "print('Tensorflow Model Prediction:', test_result)\n",
    "\n",
    "# parse the result to get the label\n",
    "result_label = np.argmax(test_result)\n",
    "\n",
    "print('Tensorflow Model Prediction:', result_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONTROLLER\n",
    "IN NATURE - THE BAYESIAN OPTIMIZATION FRAMEWORK FOR OPTIMIZATION AND CONTROLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the bayesian optimization algorithm, will be covered in the next section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BAYESIAN OPTIMIZATION FRAMEWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install PyQt5\n",
    "# %pip install colorama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use pop-up window for plots\n",
    "# %matplotlib qt5 \n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "# from matplotlib.animation import FuncAnimation\n",
    "# # print control\n",
    "# from colorama import init, Fore, Back, Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURABLE PARAMETERS\n",
    "\n",
    "## Hyperparameters\n",
    "noise_lvl = 0.1\n",
    "k_alpha = 1\n",
    "k_lambda = 1\n",
    "\n",
    "## Process Control\n",
    "num_init_points = 15\n",
    "num_iter = 20\n",
    "tolerance = 1e-3\n",
    "gap = np.inf\n",
    "\n",
    "## Acquisition Function - UCB\n",
    "ucb_beta = 1\n",
    "\n",
    "## Acquisition Function - PI & EI\n",
    "xi=0.01\n",
    "\n",
    "## Bonus factor for evaluation\n",
    "bonus_factor = 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Search Space\n",
    "### parameter 1 - a\n",
    "lb_a = para_a_lb\n",
    "print('Lower Bound of para_a:', lb_a)\n",
    "ub_a = para_a_ub\n",
    "print('Upper Bound of para_a:', ub_a)\n",
    "c_a = (ub_a + lb_a) / 2\n",
    "\n",
    "### parameter 2 - b\n",
    "lb_b = para_b_lb\n",
    "print('Lower Bound of para_b:', lb_b)\n",
    "ub_b = para_b_ub\n",
    "print('Upper Bound of para_b:', ub_b)\n",
    "c_b = (ub_b + lb_b) / 2\n",
    "print(c_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Problem / System to Optimize\n",
    "\n",
    "Triggering Mechanismï¼š Triggering Parameters In; Evaluation Index Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE OBJECTIVE FUNCTION\n",
    "def objective_function(para_a, para_b):\n",
    "\n",
    "    \"\"\" Function with unknown internals we wish to maximize.\n",
    "\n",
    "    This function defines the process to evaluate how good the parameters are for the triggering sensing mechanism.\n",
    "\n",
    "    INPUT:\n",
    "    - para_a: the threshold for the activation, positive real number\n",
    "    - para_b: activate_duration: the duration for the activation, positive integer >= 2 (as we know 1 is not error-prone in practice)\n",
    "\n",
    "    OUTPUT:\n",
    "    - evaluation value: F-beta score\n",
    "    \n",
    "    HYPERPARAMETERS:\n",
    "    - beta: the value to balance the precision and recall to calculate F-beta score\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # assistive variables\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    \n",
    "    # go through the dataset\n",
    "    for i in range(NumSample):\n",
    "    # for i in range(10):  \n",
    "        # trigger flag\n",
    "        flg_trigger = 0\n",
    "        \n",
    "        # ground truth flag\n",
    "        class_1h = np.zeros((1, num_type))\n",
    "        flg_class = 0\n",
    "        flg_interst = 0\n",
    "        \n",
    "        # get the response data\n",
    "        signal = RESPONSE[i, :].reshape(1, LenTS)\n",
    "        \n",
    "        # get the triggering mechanism\n",
    "        flg_trigger, trig_pos = trig.activation(signal, para_a, para_b)\n",
    "        \n",
    "        # print('Trigger Flag:', flg_trigger)\n",
    "        \n",
    "        # preprocess the signal for the CNN model to get the ground truth\n",
    "        signal = prenn.prenn(signal, dt, nperseg, nn_in_len)\n",
    "        \n",
    "        signal = signal.reshape(1, nn_in_len, 1)\n",
    "\n",
    "        # get the ground truth\n",
    "        class_1h = CNN_Model.predict(signal, verbose=0)\n",
    "        flag_class = np.argmax(class_1h)\n",
    "        \n",
    "        # get the ground truth\n",
    "        if flag_class > 0:\n",
    "            flg_interst = 1\n",
    "\n",
    "        # get the confusion matrix - as the number of interested data is assumed to be small, we need to consider the ratio - only two classes - interested and non-interested\n",
    "        if flg_trigger == 1 and flg_interst == 1:\n",
    "            TP += 1\n",
    "        elif flg_trigger == 1 and flg_interst == 0:\n",
    "            FP += 1\n",
    "        elif flg_trigger == 0 and flg_interst == 1:\n",
    "            FN = -1 # no use, recall will be calculated in other way\n",
    "        elif flg_trigger == 0 and flg_interst == 0:\n",
    "            TN = -1 # no use, recall will be calculated in other way\n",
    "        else:\n",
    "            print('Error in Confusion Matrix Calculation')\n",
    "    \n",
    "    # recall = Precision_Model\n",
    "    std_av = np.std(RESPONSE_AV[0, :])\n",
    "    recall_input = np.array([std_av, para_a, para_b]).reshape(1, 3)\n",
    "    recall = Recall_Model.predict(recall_input)\n",
    "    recall = float(recall)\n",
    "    \n",
    "    if recall > 1:\n",
    "        recall = 1\n",
    "    if recall < 0:\n",
    "        recall = 0\n",
    "    \n",
    "    # calculate precision\n",
    "    precision = TP / (TP + FP)\n",
    "            \n",
    "    # calculate the F-beta score\n",
    "    denominator = (beta**2) * precision + recall \n",
    "    if denominator == 0:\n",
    "        F_beta = 0\n",
    "    else:\n",
    "        F_beta = (1 + beta**2) * precision * recall / denominator\n",
    "    \n",
    "    # if F_beta is NaN, return 0\n",
    "    if np.isnan(F_beta):\n",
    "        F_beta = 0\n",
    "        return 0\n",
    "    \n",
    "    if precision > 0.9 and recall > 0.9:\n",
    "        F_beta = F_beta * bonus_factor\n",
    "\n",
    "    \n",
    "    \n",
    "    # print TP, FP, FN, TN as integer, Precision, Recall, F-beta as float number with 4 decimal places\n",
    "    # print('para_a / para_b /TP / FP / FN / TN / Precision / Recall / F-beta:', para_a, para_b, TP, FP, FN, TN, f'{precision:.4f}', f'{recall:.4f}', f'{F_beta:.4f}')  \n",
    "    # print('para_a / para_b ', para_a, para_b)  \n",
    "    # print('TP / FP / FN / TN / Precision / Recall / F-beta:', TP, FP, FN, TN)  \n",
    "    # print('Precision / Recall / F-beta:', f'{precision:.4f}', f'{recall:.4f}', f'{F_beta:.4f}')  \n",
    "    print(f'para_a / para_b / TP / FP / FN / TN / Precision / Recall / F-beta: {para_a} {para_b} {int(TP)} {int(FP)} {int(FN)} {int(TN)} {precision:.4f} {recall:.4f} {F_beta:.4f}')\n",
    "\n",
    "    return F_beta, TP, FP, FN, TN, precision, recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE SURROGATE MODEL - Gaussian Process - Kernel Function\n",
    "## Matern 2.5 as the kernel function\n",
    "def kernel(p1, p2, matern_alpha = 1, matern_lambda = 1):\n",
    "    # define the distance between two points p1 and p2\n",
    "    d= np.linalg.norm(p1 - p2)\n",
    "    k = matern_alpha * (1 + np.sqrt(5) * d / matern_lambda + 5 * d**2 / (3 * matern_lambda**2)) * np.exp(-np.sqrt(5) * d / matern_lambda)\n",
    "    return k\n",
    "\n",
    "## Mean and Variance of the Gaussian Process\n",
    "def mean_var(x, D, K_alpha, k_lambda):\n",
    "    # assume x is a variable of 1x1\n",
    "    # calculate the mean and variance of the Gaussian Process\n",
    "    x_dim = x.shape[1] # assume each colum is a dimension of x\n",
    "    num_D = D.shape[0] # number of data points in D\n",
    "    \n",
    "    Ktt = np.zeros((num_D, num_D))\n",
    "    for i in range(num_D):\n",
    "        for j in range(num_D):\n",
    "            Ktt[i, j] = kernel(D[i,:-1], D[j,:-1], K_alpha, k_lambda)\n",
    "    Kttn = Ktt + np.eye(num_D) * noise_lvl\n",
    "    IKttn = np.linalg.inv(Kttn)\n",
    "    \n",
    "    Kpt = np.zeros((1, num_D))\n",
    "    for i in range(num_D):\n",
    "        Kpt[0, i] = kernel(x, D[i,:-1], K_alpha, k_lambda)\n",
    "    Ktp = Kpt.T\n",
    "    Kpp = kernel(x, x, K_alpha, k_lambda)\n",
    "    \n",
    "    y = D[:,-1].reshape(-1,1)\n",
    "    \n",
    "    mean = Kpt @ IKttn @ y\n",
    "    var = Kpp - Kpt @ IKttn @ Ktp\n",
    "        \n",
    "    return mean, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE ACQUISITION FUNCTION - UPPER CONFIDENCE BOUND\n",
    "def S(x, D):\n",
    "    mean, var = mean_var(x, D, k_alpha, k_lambda)\n",
    "    s = mean + ucb_beta * np.sqrt(var)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_cdf(x):\n",
    "    \"\"\"\n",
    "    standard normal cumulative distribution function\n",
    "    \n",
    "    \"\"\"\n",
    "    return 0.5 * (1 + np.math.erf(x / np.sqrt(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_pdf(x):\n",
    "    \"\"\"\n",
    "    standard normal probability density function\n",
    "    \"\"\"\n",
    "    return (1 / np.sqrt(2 * np.pi)) * np.exp(-0.5 * x ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE ACQUISITION FUNCTION - PROBABILITY OF IMPROVEMENT\n",
    "def S_PI(x, D, xi=0.01):\n",
    "    f_best = np.max(D[:,-1])\n",
    "    mean, var = mean_var(x, D, k_alpha, k_lambda)\n",
    "    z = (mean - f_best - xi) / np.sqrt(var)\n",
    "    s = norm_cdf(z)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE ACQUISITION FUNCTION - EXPECTATION OF IMPROVEMENT\n",
    "def S_EI(x, D, xi=0.01):\n",
    "    f_best = np.max(D[:,-1])\n",
    "    mean, var = mean_var(x, D, k_alpha, k_lambda)\n",
    "    z = (mean - f_best - xi) / np.sqrt(var)\n",
    "    s = (mean - f_best - xi) * norm_cdf(z) + np.sqrt(var) * norm_pdf(z)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE OPTIMIZATION FUNCTION FOR THE ACQUISITION FUNCTION\n",
    "def optimize_acquisition(D):\n",
    "    # randomly search for the point with the highest acquisition function value\n",
    "    num_search = 100\n",
    "    max_s = -np.inf\n",
    "    max_x = None\n",
    "    cur_x = np.zeros((1,2))\n",
    "    for i in range(num_search):\n",
    "        cur_x[0,0] = np.random.uniform(lb_a, ub_a)\n",
    "        cur_x[0,1] = np.random.uniform(lb_b, ub_b)\n",
    "        cur_s = S(cur_x, D) # UCB\n",
    "        # cur_s = S_PI(cur_x, D, xi) # PI\n",
    "        # cur_s = S_EI(cur_x, D, xi) # EI\n",
    "        if cur_s > max_s:\n",
    "            max_s = cur_s\n",
    "            max_x = cur_x.copy()\n",
    "    return max_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Optimization Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data in STAGE II - D\n",
    "D_Path = r\"../01-PRE-DEPLOYMENT/05-PRE-OPTIMIZATION/D.npy\"\n",
    "\n",
    "D = np.load(D_Path)\n",
    "\n",
    "stage_virtual_num = D.shape[0]\n",
    "\n",
    "print('Number of Data Points in pre-optimization (D number):', stage_virtual_num)\n",
    "\n",
    "DD_Path = r\"../01-PRE-DEPLOYMENT/05-PRE-OPTIMIZATION/DD.npy\"\n",
    "\n",
    "DD = np.load(DD_Path)\n",
    "\n",
    "print('Number of Data Points in pre-optimization (DD number):', DD.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = np.max(D[:,2])\n",
    "print('Initial Maximum Value:', max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_a = 0.014\n",
    "com_b = 5\n",
    "comparison = objective_function(com_a, com_b)\n",
    "com_f_beta = comparison[0]\n",
    "com_recall = comparison[-2]\n",
    "com_precision = comparison[-1]\n",
    "print('Comparison F-beta:', com_f_beta)\n",
    "print('Comparison Recall:', com_recall)\n",
    "print('Comparison Precision:', com_precision)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
