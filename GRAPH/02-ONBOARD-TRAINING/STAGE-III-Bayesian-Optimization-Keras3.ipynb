{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAGE III - REAL WORLD OPTIMIZATION\n",
    "\n",
    "![FIGURE](STAGE-III.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEPENDENCIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMON\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Triggering Mechanism\n",
    "import triggering as trig\n",
    "\n",
    "# Signal Processing\n",
    "from scipy import signal  # for signal processing\n",
    "from scipy.signal import hilbert  # for signal processing\n",
    "import prenn # for deep learning\n",
    "\n",
    "# AI\n",
    "import keras\n",
    "\n",
    "import tensorflow as tf # for deep learning\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.callbacks import TensorBoard # for visualization\n",
    "\n",
    "import onnxruntime as ort # for onnx runtime\n",
    "\n",
    "# Visualization\n",
    "# %matplotlib qt5\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.animation import FuncAnimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLOSED-LOOP CONTROL COMPONENTS SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENVIRONMENT\n",
    "\n",
    "IN NATURE - THE SYNTHESIZED RESPONSE DATA - DIFFERENT FROM STAGE II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrected Paths\n",
    "AVPath = r'../01-PRE-DEPLOYMENT/DATA/VAL_RES/VAL_DATA_AV.npy' \n",
    "EQPath = r'../01-PRE-DEPLOYMENT/DATA/VAL_RES/VAL_DATA_EQ.npy'\n",
    "IPPath = r'../01-PRE-DEPLOYMENT/DATA/VAL_RES/VAL_DATA_IP.npy'\n",
    "SWPath = r'../01-PRE-DEPLOYMENT/DATA/VAL_RES/VAL_DATA_SW.npy'\n",
    "\n",
    "# Load Data\n",
    "RESPONSE_AV = np.load(AVPath)\n",
    "RESPONSE_EQ = np.load(EQPath)\n",
    "RESPONSE_IP = np.load(IPPath)\n",
    "RESPONSE_SW = np.load(SWPath)\n",
    "\n",
    "## only use part of the data\n",
    "raw_len_av = RESPONSE_AV.shape[0]\n",
    "raw_len_eq = RESPONSE_EQ.shape[0]\n",
    "raw_len_ip = RESPONSE_IP.shape[0]\n",
    "raw_len_sw = RESPONSE_SW.shape[0]\n",
    "\n",
    "# this is to simulate the imbalanced data - ensure the same ratio within STAGE III\n",
    "ratio_aw = 0.6\n",
    "ratio_eq = 1\n",
    "ratio_ip = 1\n",
    "ratio_sw = 1\n",
    "\n",
    "uselen_aw = int(raw_len_av * ratio_aw)\n",
    "uselen_eq = int(raw_len_eq * ratio_eq)  \n",
    "uselen_ip = int(raw_len_ip * ratio_ip)\n",
    "uselen_sw = int(raw_len_sw * ratio_sw)\n",
    "\n",
    "# randomly pick uselen_aw samples from RESPONSE_XX, no repeat\n",
    "idx_aw = random.sample(range(raw_len_av), uselen_aw)\n",
    "idx_eq = random.sample(range(raw_len_eq), uselen_eq)\n",
    "idx_ip = random.sample(range(raw_len_ip), uselen_ip)\n",
    "idx_sw = random.sample(range(raw_len_sw), uselen_sw)\n",
    "\n",
    "RESPONSE_AV = RESPONSE_AV[idx_aw]\n",
    "RESPONSE_EQ = RESPONSE_EQ[idx_eq]\n",
    "RESPONSE_IP = RESPONSE_IP[idx_ip]\n",
    "RESPONSE_SW = RESPONSE_SW[idx_sw]\n",
    "\n",
    "## Check Data Info\n",
    "print(type(RESPONSE_AV))\n",
    "print('RESPONSE_AV Shape:', RESPONSE_AV.shape)\n",
    "print(type(RESPONSE_EQ))\n",
    "print('RESPONSE_EQ Shape:', RESPONSE_EQ.shape)\n",
    "print(type(RESPONSE_IP))\n",
    "print('RESPONSE_IP Shape:', RESPONSE_IP.shape)\n",
    "print(type(RESPONSE_SW))\n",
    "print('RESPONSE_SW Shape:', RESPONSE_SW.shape)\n",
    "\n",
    "num_type = 4\n",
    "\n",
    "signal_length = RESPONSE_AV.shape[1]\n",
    "\n",
    "LenTS = signal_length\n",
    "\n",
    "# ratio of non-interested data to interested data\n",
    "ratio_ni = RESPONSE_AV.shape[0] / (RESPONSE_EQ.shape[0] + RESPONSE_IP.shape[0] + RESPONSE_SW.shape[0])\n",
    "\n",
    "print('Ratio of Non-Interested Data to Interested Data:', ratio_ni)\n",
    "\n",
    "## Stack Data\n",
    "RESPONSE = np.vstack((RESPONSE_AV, RESPONSE_EQ, RESPONSE_IP, RESPONSE_SW))\n",
    "\n",
    "## Total Number of Samples\n",
    "NumSample = RESPONSE.shape[0]\n",
    "print('Total Number of Samples:', NumSample) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_AV = RESPONSE_AV.shape[0]\n",
    "NUM_EQ = RESPONSE_EQ.shape[0]\n",
    "NUM_IP = RESPONSE_IP.shape[0]\n",
    "NUM_SW = RESPONSE_SW.shape[0]\n",
    "\n",
    "#print\n",
    "print('Number of AV:', NUM_AV)\n",
    "print('Number of EQ:', NUM_EQ)\n",
    "print('Number of IP:', NUM_IP)\n",
    "print('Number of SW:', NUM_SW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SYSTEM\n",
    "IN NATURE - THE TRIGGERING MECHANISM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embodied in the triggering.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the search space by check the maximum and minimum of the data - ambient vibration\n",
    "max_noise = np.max(abs(RESPONSE_AV))\n",
    "min_noise = np.min(abs(RESPONSE_AV))\n",
    "print('Maximum of AV:', max_noise)\n",
    "print('Minimum of AV:', min_noise)\n",
    "\n",
    "# determine the lower and upper bound of the search space\n",
    "ub_factor = 2\n",
    "lb_factor = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration\n",
    "\n",
    "## para_a stands for the triggering threshold amplitude (continuous)\n",
    "para_a_lb = lb_factor*(max_noise + min_noise)/2\n",
    "para_a_ub = ub_factor*(max_noise + min_noise)/2\n",
    "\n",
    "print('Lower Bound of para_a:', para_a_lb)\n",
    "print('Upper Bound of para_a:', para_a_ub)\n",
    "\n",
    "## para_b stands for the triggering threshold duration (discrete integer)\n",
    "para_b_lb = 2\n",
    "para_b_ub = 10\n",
    "\n",
    "print('Lower Bound of para_b:', para_b_lb)\n",
    "print('Upper Bound of para_b:', para_b_ub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_data = RESPONSE_AV[0]\n",
    "\n",
    "para_a = 0.5\n",
    "para_b = 2\n",
    "\n",
    "trig_flg = trig.activation(test_data, para_a, para_b)\n",
    "print(trig_flg[0]) # the first element stands for the triggering flag, and the second element stands for the triggering time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESTIMATOR\n",
    "IN NATURE - TRIGGERING MECHANISM & GROUND TRUTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 1.75 # beta value to balance the precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USED PARAMETER of the Dataset\n",
    "\n",
    "# nn_in_len = 128 # nn input length can be automatically calculated from the model input size\n",
    "dt = 0.01  # time step, change according to the dataset\n",
    "nperseg = 128 # number of points for each segment in spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier - CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Classifier Model Path\n",
    "classifier_model_path = r'../01-PRE-DEPLOYMENT/03-NN-TRAINING-CNN/cnn_model.keras'\n",
    "CNN_Model = keras.saving.load_model(classifier_model_path)\n",
    "CNN_Model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictor - DNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN Predictor Model Path\n",
    "recall_model_path = r'../01-PRE-DEPLOYMENT/04-NN-TRAINING-DNN/recall_est.keras'\n",
    "Recall_Model = keras.saving.load_model(recall_model_path)\n",
    "Recall_Model.summary()\n",
    "\n",
    "# DNN Predictor Model Path\n",
    "precision_model_path = r'../01-PRE-DEPLOYMENT/04-NN-TRAINING-DNN/precision_est.keras'\n",
    "Precision_Model = keras.saving.load_model(precision_model_path)\n",
    "Precision_Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the input data length\n",
    "nn_in_len = CNN_Model.input_shape[1]\n",
    "print('Input Data Length:', nn_in_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model test by loading a piece of data from the dataset, and feed intot he prenn function\n",
    "\n",
    "# index for the random data\n",
    "idx = np.random.randint(NumSample)\n",
    "\n",
    "# get the data\n",
    "test_data = RESPONSE[idx, :].reshape(1, LenTS)\n",
    "\n",
    "print('Test Data Shape:', test_data.shape)\n",
    "\n",
    "# plot the test data\n",
    "plt.figure()\n",
    "plt.plot(test_data[0, :])\n",
    "plt.title('Test Data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess\n",
    "output_length = nn_in_len\n",
    "test_data = prenn.prenn(test_data, dt, nperseg, output_length)\n",
    "\n",
    "# print the preprocessed data\n",
    "plt.figure()\n",
    "plt.plot(test_data[0, :])\n",
    "plt.title('Preprocessed Test Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.reshape(1, nn_in_len, 1)\n",
    "\n",
    "print('Preprocessed Test Data Shape:', test_data.shape)\n",
    "\n",
    "# test the model\n",
    "test_result = CNN_Model.predict(test_data)\n",
    "print('Tensorflow Model Prediction:', test_result)\n",
    "\n",
    "# parse the result to get the label\n",
    "result_label = np.argmax(test_result)\n",
    "\n",
    "print('Tensorflow Model Prediction:', result_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONTROLLER\n",
    "IN NATURE - THE BAYESIAN OPTIMIZATION FRAMEWORK FOR OPTIMIZATION AND CONTROLL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the bayesian optimization algorithm, will be covered in the next section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BAYESIAN OPTIMIZATION FRAMEWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install PyQt5\n",
    "# %pip install colorama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use pop-up window for plots\n",
    "# %matplotlib qt5 \n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "# from matplotlib.animation import FuncAnimation\n",
    "# # print control\n",
    "# from colorama import init, Fore, Back, Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURABLE PARAMETERS\n",
    "\n",
    "## Hyperparameters\n",
    "noise_lvl = 0.1\n",
    "k_alpha = 1\n",
    "k_lambda = 1\n",
    "\n",
    "## Process Control\n",
    "num_init_points = 15\n",
    "num_iter = 20\n",
    "tolerance = 1e-3\n",
    "gap = np.inf\n",
    "\n",
    "## Acquisition Function - UCB\n",
    "ucb_beta = 1\n",
    "\n",
    "## Acquisition Function - PI & EI\n",
    "xi=0.01\n",
    "\n",
    "## Bonus factor for evaluation\n",
    "bonus_factor = 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Search Space\n",
    "### parameter 1 - a\n",
    "lb_a = para_a_lb\n",
    "print('Lower Bound of para_a:', lb_a)\n",
    "ub_a = para_a_ub\n",
    "print('Upper Bound of para_a:', ub_a)\n",
    "c_a = (ub_a + lb_a) / 2\n",
    "\n",
    "### parameter 2 - b\n",
    "lb_b = para_b_lb\n",
    "print('Lower Bound of para_b:', lb_b)\n",
    "ub_b = para_b_ub\n",
    "print('Upper Bound of para_b:', ub_b)\n",
    "c_b = (ub_b + lb_b) / 2\n",
    "print(c_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Problem / System to Optimize\n",
    "\n",
    "Triggering Mechanismï¼š Triggering Parameters In; Evaluation Index Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE OBJECTIVE FUNCTION (for manual setup evaluation)\n",
    "def objective_function_manual(para_a, para_b):\n",
    "\n",
    "    \"\"\" Function with unknown internals we wish to maximize.\n",
    "\n",
    "    This function defines the process to evaluate how good the parameters are for the triggering sensing mechanism.\n",
    "\n",
    "    INPUT:\n",
    "    - para_a: the threshold for the activation, positive real number\n",
    "    - para_b: activate_duration: the duration for the activation, positive integer >= 2 (as we know 1 is not error-prone in practice)\n",
    "\n",
    "    OUTPUT:\n",
    "    - evaluation value: F-beta score\n",
    "    \n",
    "    HYPERPARAMETERS:\n",
    "    - beta: the value to balance the precision and recall to calculate F-beta score\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # assistive variables\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    \n",
    "    # go through the dataset\n",
    "    for i in range(NumSample):\n",
    "    # for i in range(10):  \n",
    "        # trigger flag\n",
    "        flg_trigger = 0\n",
    "        \n",
    "        # ground truth flag\n",
    "        flg_class = 0\n",
    "        flg_interst = 0\n",
    "        \n",
    "        # get the response data\n",
    "        signal = RESPONSE[i, :].reshape(1, -1)\n",
    "        \n",
    "        # get the triggering mechanism\n",
    "        flg_trigger, trig_pos = trig.activation(signal, para_a, para_b)\n",
    "        \n",
    "        # print('Trigger Flag:', flg_trigger)\n",
    "        \n",
    "        # get the ground truth\n",
    "        if i < NUM_AV:\n",
    "            flg_interst = 0\n",
    "            flag_class = 0\n",
    "        elif i < NUM_AV + NUM_EQ:\n",
    "            flg_interst = 1\n",
    "            flag_class = 1\n",
    "        elif i < NUM_AV + NUM_EQ + NUM_IP:\n",
    "            flg_interst = 1\n",
    "            flag_class = 2\n",
    "        else:\n",
    "            flg_interst = 1\n",
    "            flag_class = 3\n",
    "\n",
    "        # get the confusion matrix - as the number of interested data is assumed to be small, we need to consider the ratio - only two classes - interested and non-interested\n",
    "        if flg_trigger == 1 and flg_interst == 1:\n",
    "            TP += 1*ratio_ni\n",
    "        elif flg_trigger == 1 and flg_interst == 0:\n",
    "            FP += 1\n",
    "        elif flg_trigger == 0 and flg_interst == 1:\n",
    "            FN += 1*ratio_ni\n",
    "        elif flg_trigger == 0 and flg_interst == 0:\n",
    "            TN += 1\n",
    "        else:\n",
    "            print('Error in Confusion Matrix Calculation')\n",
    "            \n",
    "    # demoninator\n",
    "    denominator = ((1 + beta**2) * TP + beta**2 * FN + FP)\n",
    "    if denominator == 0:\n",
    "        F_beta = 0\n",
    "        return 0\n",
    "    \n",
    "    F_beta = (1 + beta**2) * TP / ((1 + beta**2) * TP + beta**2 * FN + FP)\n",
    "    \n",
    "    # if F_beta is NaN, return 0\n",
    "    if np.isnan(F_beta):\n",
    "        F_beta = 0\n",
    "        return 0\n",
    "    \n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    \n",
    "    if precision > 0.9 and recall > 0.9:\n",
    "        F_beta = F_beta * bonus_factor\n",
    "    \n",
    "    # print TP, FP, FN, TN as integer, Precision, Recall, F-beta as float number with 4 decimal places\n",
    "    print(f'para_a / para_b / TP / FP / FN / TN / Precision / Recall / F-beta: {para_a} {para_b} {int(TP)} {int(FP)} {int(FN)} {int(TN)} {precision:.4f} {recall:.4f} {F_beta:.4f}')\n",
    "\n",
    "\n",
    "    return F_beta, TP, FP, FN, TN, precision, recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST / MANUAL CHECK\n",
    "\n",
    "para_a = 0.00648\n",
    "para_b = 2\n",
    "\n",
    "manual_setup = objective_function_manual(para_a, para_b)\n",
    "\n",
    "manual_f_beta = manual_setup[0]\n",
    "\n",
    "manual_precision = manual_setup[-2]\n",
    "\n",
    "manual_recall = manual_setup[-1]\n",
    "\n",
    "print('Manual F-beta:', manual_f_beta)\n",
    "\n",
    "print('Manual Precision:', manual_precision)\n",
    "\n",
    "print('Manual Recall:', manual_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE OBJECTIVE FUNCTION (for onboard fine tuning)\n",
    "def objective_function(para_a, para_b):\n",
    "\n",
    "    \"\"\" Function with unknown internals we wish to maximize.\n",
    "\n",
    "    This function defines the process to evaluate how good the parameters are for the triggering sensing mechanism.\n",
    "\n",
    "    INPUT:\n",
    "    - para_a: the threshold for the activation, positive real number\n",
    "    - para_b: activate_duration: the duration for the activation, positive integer >= 2 (as we know 1 is not error-prone in practice)\n",
    "\n",
    "    OUTPUT:\n",
    "    - evaluation value: F-beta score\n",
    "    \n",
    "    HYPERPARAMETERS:\n",
    "    - beta: the value to balance the precision and recall to calculate F-beta score\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # assistive variables\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    \n",
    "    # go through the dataset\n",
    "    for i in range(NumSample):\n",
    "    # for i in range(10):  \n",
    "        # trigger flag\n",
    "        flg_trigger = 0\n",
    "        \n",
    "        # ground truth flag\n",
    "        class_1h = np.zeros((1, num_type))\n",
    "        flg_class = 0\n",
    "        flg_interst = 0\n",
    "        \n",
    "        # get the response data\n",
    "        signal = RESPONSE[i, :].reshape(1, LenTS)\n",
    "        \n",
    "        # get the triggering mechanism\n",
    "        flg_trigger, trig_pos = trig.activation(signal, para_a, para_b)\n",
    "        \n",
    "        # print('Trigger Flag:', flg_trigger)\n",
    "        \n",
    "        # preprocess the signal for the CNN model to get the ground truth\n",
    "        signal = prenn.prenn(signal, dt, nperseg, nn_in_len)\n",
    "        \n",
    "        signal = signal.reshape(1, nn_in_len, 1)\n",
    "\n",
    "        # get the ground truth\n",
    "        class_1h = CNN_Model.predict(signal, verbose=0)\n",
    "        flag_class = np.argmax(class_1h)\n",
    "        \n",
    "        # get the ground truth\n",
    "        if flag_class > 0:\n",
    "            flg_interst = 1\n",
    "\n",
    "        # get the confusion matrix - as the number of interested data is assumed to be small, we need to consider the ratio - only two classes - interested and non-interested\n",
    "        if flg_trigger == 1 and flg_interst == 1:\n",
    "            TP += 1\n",
    "        elif flg_trigger == 1 and flg_interst == 0:\n",
    "            FP += 1\n",
    "        elif flg_trigger == 0 and flg_interst == 1:\n",
    "            FN = -1 # no use, recall will be calculated in other way\n",
    "        elif flg_trigger == 0 and flg_interst == 0:\n",
    "            TN = -1 # no use, recall will be calculated in other way\n",
    "        else:\n",
    "            print('Error in Confusion Matrix Calculation')\n",
    "    \n",
    "    # recall = Precision_Model\n",
    "    std_av = np.std(RESPONSE_AV[0, :])\n",
    "    recall_input = np.array([std_av, para_a, para_b]).reshape(1, 3)\n",
    "    recall = Recall_Model.predict(recall_input)\n",
    "    recall = float(recall)\n",
    "    \n",
    "    # if recall > 1:\n",
    "    #     recall = 1\n",
    "    # if recall < 0:\n",
    "    #     recall = 0\n",
    "    \n",
    "    # calculate precision\n",
    "    precision = TP / (TP + FP)\n",
    "            \n",
    "    # calculate the F-beta score\n",
    "    denominator = (beta**2) * precision + recall \n",
    "    if denominator == 0:\n",
    "        F_beta = 0\n",
    "    else:\n",
    "        F_beta = (1 + beta**2) * precision * recall / denominator\n",
    "    \n",
    "    # if F_beta is NaN, return 0\n",
    "    if np.isnan(F_beta):\n",
    "        F_beta = 0\n",
    "        return 0\n",
    "    \n",
    "    if precision > 0.9 and recall > 0.9:\n",
    "        F_beta = F_beta * bonus_factor\n",
    "\n",
    "    \n",
    "    \n",
    "    # print TP, FP, FN, TN as integer, Precision, Recall, F-beta as float number with 4 decimal places\n",
    "    # print('para_a / para_b /TP / FP / FN / TN / Precision / Recall / F-beta:', para_a, para_b, TP, FP, FN, TN, f'{precision:.4f}', f'{recall:.4f}', f'{F_beta:.4f}')  \n",
    "    # print('para_a / para_b ', para_a, para_b)  \n",
    "    # print('TP / FP / FN / TN / Precision / Recall / F-beta:', TP, FP, FN, TN)  \n",
    "    # print('Precision / Recall / F-beta:', f'{precision:.4f}', f'{recall:.4f}', f'{F_beta:.4f}')  \n",
    "    print(f'para_a / para_b / TP / FP / FN / TN / Precision / Recall / F-beta: {para_a} {para_b} {int(TP)} {int(FP)} {int(FN)} {int(TN)} {precision:.4f} {recall:.4f} {F_beta:.4f}')\n",
    "\n",
    "    return F_beta, TP, FP, FN, TN, precision, recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE SURROGATE MODEL - Gaussian Process - Kernel Function\n",
    "## Matern 2.5 as the kernel function\n",
    "def kernel(p1, p2, matern_alpha = 1, matern_lambda = 1):\n",
    "    # define the distance between two points p1 and p2\n",
    "    d= np.linalg.norm(p1 - p2)\n",
    "    k = matern_alpha * (1 + np.sqrt(5) * d / matern_lambda + 5 * d**2 / (3 * matern_lambda**2)) * np.exp(-np.sqrt(5) * d / matern_lambda)\n",
    "    return k\n",
    "\n",
    "## Mean and Variance of the Gaussian Process\n",
    "def mean_var(x, D, K_alpha, k_lambda):\n",
    "    # assume x is a variable of 1x1\n",
    "    # calculate the mean and variance of the Gaussian Process\n",
    "    x_dim = x.shape[1] # assume each colum is a dimension of x\n",
    "    num_D = D.shape[0] # number of data points in D\n",
    "    \n",
    "    Ktt = np.zeros((num_D, num_D))\n",
    "    for i in range(num_D):\n",
    "        for j in range(num_D):\n",
    "            Ktt[i, j] = kernel(D[i,:-1], D[j,:-1], K_alpha, k_lambda)\n",
    "    Kttn = Ktt + np.eye(num_D) * noise_lvl\n",
    "    IKttn = np.linalg.inv(Kttn)\n",
    "    \n",
    "    Kpt = np.zeros((1, num_D))\n",
    "    for i in range(num_D):\n",
    "        Kpt[0, i] = kernel(x, D[i,:-1], K_alpha, k_lambda)\n",
    "    Ktp = Kpt.T\n",
    "    Kpp = kernel(x, x, K_alpha, k_lambda)\n",
    "    \n",
    "    y = D[:,-1].reshape(-1,1)\n",
    "    \n",
    "    mean = Kpt @ IKttn @ y\n",
    "    var = Kpp - Kpt @ IKttn @ Ktp\n",
    "        \n",
    "    return mean, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE ACQUISITION FUNCTION - UPPER CONFIDENCE BOUND\n",
    "def S(x, D):\n",
    "    mean, var = mean_var(x, D, k_alpha, k_lambda)\n",
    "    s = mean + ucb_beta * np.sqrt(var)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_cdf(x):\n",
    "    \"\"\"\n",
    "    standard normal cumulative distribution function\n",
    "    \n",
    "    \"\"\"\n",
    "    return 0.5 * (1 + np.math.erf(x / np.sqrt(2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_pdf(x):\n",
    "    \"\"\"\n",
    "    standard normal probability density function\n",
    "    \"\"\"\n",
    "    return (1 / np.sqrt(2 * np.pi)) * np.exp(-0.5 * x ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE ACQUISITION FUNCTION - PROBABILITY OF IMPROVEMENT\n",
    "def S_PI(x, D, xi=0.01):\n",
    "    f_best = np.max(D[:,-1])\n",
    "    mean, var = mean_var(x, D, k_alpha, k_lambda)\n",
    "    z = (mean - f_best - xi) / np.sqrt(var)\n",
    "    s = norm_cdf(z)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE ACQUISITION FUNCTION - EXPECTATION OF IMPROVEMENT\n",
    "def S_EI(x, D, xi=0.01):\n",
    "    f_best = np.max(D[:,-1])\n",
    "    mean, var = mean_var(x, D, k_alpha, k_lambda)\n",
    "    z = (mean - f_best - xi) / np.sqrt(var)\n",
    "    s = (mean - f_best - xi) * norm_cdf(z) + np.sqrt(var) * norm_pdf(z)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE OPTIMIZATION FUNCTION FOR THE ACQUISITION FUNCTION\n",
    "def optimize_acquisition(D):\n",
    "    # randomly search for the point with the highest acquisition function value\n",
    "    num_search = 100\n",
    "    max_s = -np.inf\n",
    "    max_x = None\n",
    "    cur_x = np.zeros((1,2))\n",
    "    for i in range(num_search):\n",
    "        cur_x[0,0] = np.random.uniform(lb_a, ub_a)\n",
    "        cur_x[0,1] = np.random.uniform(lb_b, ub_b)\n",
    "        cur_s = S(cur_x, D) # UCB\n",
    "        # cur_s = S_PI(cur_x, D, xi) # PI\n",
    "        # cur_s = S_EI(cur_x, D, xi) # EI\n",
    "        if cur_s > max_s:\n",
    "            max_s = cur_s\n",
    "            max_x = cur_x.copy()\n",
    "    return max_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Optimization Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data in STAGE II - D\n",
    "D_Path = r\"../01-PRE-DEPLOYMENT/05-PRE-OPTIMIZATION/D.npy\"\n",
    "\n",
    "D = np.load(D_Path)\n",
    "\n",
    "stage_virtual_num = D.shape[0]\n",
    "\n",
    "print('Number of Data Points in pre-optimization (D number):', stage_virtual_num)\n",
    "\n",
    "DD_Path = r\"../01-PRE-DEPLOYMENT/05-PRE-OPTIMIZATION/DD.npy\"\n",
    "\n",
    "DD = np.load(DD_Path)\n",
    "\n",
    "print('Number of Data Points in pre-optimization (DD number):', DD.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = np.max(D[:,2])\n",
    "print('Initial Maximum Value:', max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REAL WORLD OPTIMIZATION ITERATIONS\n",
    "for i in range(num_iter):\n",
    "    \n",
    "    update_flg = False\n",
    "    \n",
    "    tmp = np.zeros((1, 7)) # to store objective function value, TP, FP, FN, TN, Precision, Recall\n",
    "    \n",
    "    # (1) use the surrogate model to approach the posterior distribution of the objective function, modeled by Gaussian Process which can be characterized by the mean function and the covariance function\n",
    "    \n",
    "    ## mean, var = mean_var(x, D, 1, 1)\n",
    "    \n",
    "    # (2) determine the next point to evaluate using the acquisition function S(D)\n",
    "    x_eval = optimize_acquisition(D)\n",
    "    \n",
    "    # (3) evaluate the objective function at the next point\n",
    "    tmp = objective_function(x_eval[0,0], x_eval[0,1])\n",
    "    \n",
    "    f_eval = tmp[0]\n",
    "    \n",
    "    # (4) update the dataset D\n",
    "    newpoint = np.zeros((1,3))\n",
    "    newpoint[0,0] = x_eval[0,0]\n",
    "    newpoint[0,1] = x_eval[0,1]\n",
    "    newpoint[0,2] = f_eval\n",
    "    D = np.vstack((D, newpoint))\n",
    "\n",
    "    newpoint_d = np.zeros((1,9))\n",
    "    newpoint_d[0,0] = x_eval[0,0]\n",
    "    newpoint_d[0,1] = x_eval[0,1]\n",
    "    newpoint_d[0,2:] = tmp\n",
    "    DD = np.vstack((DD, newpoint_d))\n",
    "    \n",
    "    # # (5) check the stopping criterion\n",
    "    # gap = np.abs(D[-1, -1] - D[-2, -1])\n",
    "    # if gap < tolerance:\n",
    "    #     break\n",
    "    \n",
    "    # (5) update the global best value\n",
    "    if f_eval > max_val:\n",
    "        max_val = f_eval\n",
    "        max_x = x_eval\n",
    "        update_flg = True\n",
    "    \n",
    "    # (6) print the progress\n",
    "    if (update_flg == True):\n",
    "        print('BO Iteration:', i+1,'/', num_iter, 'Best Value Updated:', max_val, 'at', max_x)\n",
    "    else:\n",
    "        print('BO Iteration:', i+1,'/', num_iter)\n",
    "    \n",
    "    # (7) reset the flag\n",
    "    update_flg = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of points in D and DD\n",
    "print('Number of Data Points in D:', D.shape[0])\n",
    "print(D.shape[0])\n",
    "\n",
    "print('Number of Data Points in DD:', DD.shape[0])\n",
    "print(DD.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "# stem plot\n",
    "\n",
    "# Assuming D is already defined and contains your data\n",
    "# D[:, 0] -> threshold\n",
    "# D[:, 1] -> duration\n",
    "# D[:, 2] -> F-beta score\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlabel('threshold')\n",
    "ax.set_ylabel('duration')\n",
    "ax.set_zlabel('F-beta score')\n",
    "ax.set_xlim(0, 1.1*ub_a)\n",
    "ax.set_ylim(0, 1.1*ub_b)\n",
    "ax.set_zlim(0, bonus_factor)\n",
    "\n",
    "# Create stem plot\n",
    "for i in range(D.shape[0]):\n",
    "    x = D[i, 0]\n",
    "    y = D[i, 1]\n",
    "    z = D[i, 2]\n",
    "    ax.plot([x, x], [y, y], [0, z], 'k--')\n",
    "    ax.scatter(x, y, z, c='b', marker='o')\n",
    "    ax.text(x, y, z, str(i), color='black')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the final value\n",
    "print(D[-1, -1])\n",
    "\n",
    "# print the max value\n",
    "print(np.max(D[:, -1]))\n",
    "\n",
    "# print the argmax\n",
    "print(D[np.argmax(D[:, -1]), :-1])\n",
    "\n",
    "# print the row index of the max value\n",
    "print(np.argmax(D[:, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save lb_a, ub_a, lb_b, ub_b, noise_lvl, k_alpha, k_lambda, num_init_points, num_iter, tolerance, ucb_beta\n",
    "np.save('config.npy', np.array([lb_a, ub_a, lb_b, ub_b, noise_lvl, k_alpha, k_lambda, num_init_points, num_iter, tolerance, ucb_beta]))\n",
    "\n",
    "# save D to a file\n",
    "np.save('D.npy', D)\n",
    "\n",
    "# save DD to a file\n",
    "np.save('DD.npy', DD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POST PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMON\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Triggering Mechanism\n",
    "import triggering as trig\n",
    "\n",
    "# Signal Processing\n",
    "from scipy import signal  # for signal processing\n",
    "from scipy.signal import hilbert  # for signal processing\n",
    "import prenn # for deep learning\n",
    "\n",
    "# AI\n",
    "import keras\n",
    "\n",
    "import tensorflow as tf # for deep learning\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from keras.callbacks import TensorBoard # for visualization\n",
    "\n",
    "import onnxruntime as ort # for onnx runtime\n",
    "\n",
    "# Visualization\n",
    "# %matplotlib qt5\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.animation import FuncAnimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data in STAGE II - D\n",
    "DV_Path = r\"../01-PRE-DEPLOYMENT/05-PRE-OPTIMIZATION/D.npy\"\n",
    "\n",
    "DV = np.load(DV_Path)\n",
    "\n",
    "stage_virtual_num = DV.shape[0]\n",
    "\n",
    "print('Number of Data Points in Virtual Environment:', stage_virtual_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DD = np.load('DD.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "D = np.load('D.npy')\n",
    "\n",
    "# Get the number of rows in D\n",
    "num_D = D.shape[0]\n",
    "\n",
    "# Define stage_virtual_num to determine the cutoff for red vs. blue\n",
    "stage_virtual_num = 65  # Set your desired value for stage_virtual_num, ensure it's an integer\n",
    "\n",
    "# -----------------------\n",
    "# Customization variables:\n",
    "# -----------------------\n",
    "FONT_FAMILY = 'Times New Roman'    # Global font family\n",
    "GLOBAL_FONT_SIZE = 18              # Global font size for texts\n",
    "AXIS_TITLE_FONT_SIZE = 30          # Font size for axis titles\n",
    "TICK_FONT_SIZE = 18                # Font size for axis tick labels\n",
    "MARKER_SIZE = 10                   # Marker size for scatter points (enlarged for better visibility)\n",
    "\n",
    "# Color definitions for the red and blue color scales:\n",
    "RED_LIGHT = 'rgb(255, 200, 200)'     # Light red\n",
    "RED_DARK = 'rgb(139, 0, 0)'           # Dark red\n",
    "BLUE_LIGHT = 'rgb(200, 200, 255)'     # Light blue\n",
    "BLUE_DARK = 'rgb(0, 0, 139)'          # Dark blue\n",
    "\n",
    "# -----------------------\n",
    "# Split the data into parts\n",
    "# -----------------------\n",
    "thresholds = D[:, 0]\n",
    "durations = D[:, 1]\n",
    "F_beta = D[:, 2]\n",
    "\n",
    "# Create a 3D scatter plot\n",
    "fig = go.Figure()\n",
    "\n",
    "# Define red color scale using the customization variables\n",
    "red_colorscale = [\n",
    "    [0.0, RED_LIGHT],\n",
    "    [1.0, RED_DARK]\n",
    "]\n",
    "\n",
    "# Add red-colored points for the first stage_virtual_num data\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=thresholds[:stage_virtual_num],      # x-axis data (first part)\n",
    "    y=durations[:stage_virtual_num],         # y-axis data (first part)\n",
    "    z=F_beta[:stage_virtual_num],            # z-axis data (first part)\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=MARKER_SIZE,\n",
    "        color=F_beta[:stage_virtual_num],    # color determined by F-beta values\n",
    "        colorscale=red_colorscale,\n",
    "        showscale=False                      # Cancel colorbar\n",
    "    ),\n",
    "    name='Virtual Environment Optimization',\n",
    "    showlegend=False                         # Cancel legend\n",
    "))\n",
    "\n",
    "# Define blue color scale using the customization variables\n",
    "blue_colorscale = [\n",
    "    [0.0, BLUE_LIGHT],\n",
    "    [1.0, BLUE_DARK]\n",
    "]\n",
    "\n",
    "# Add blue-colored points for the remaining data\n",
    "fig.add_trace(go.Scatter3d(\n",
    "    x=thresholds[stage_virtual_num:],      # x-axis data (second part)\n",
    "    y=durations[stage_virtual_num:],         # y-axis data (second part)\n",
    "    z=F_beta[stage_virtual_num:],            # z-axis data (second part)\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=MARKER_SIZE,\n",
    "        color=F_beta[stage_virtual_num:],    # color determined by F-beta values\n",
    "        colorscale=blue_colorscale,\n",
    "        showscale=False                      # Cancel colorbar\n",
    "    ),\n",
    "    name='Real World Optimization',\n",
    "    showlegend=False                         # Cancel legend\n",
    "))\n",
    "\n",
    "# Set axis labels, fonts, axis limits, and ranges\n",
    "fig.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis=dict(\n",
    "            title='Threshold',\n",
    "            titlefont=dict(family=FONT_FAMILY, size=AXIS_TITLE_FONT_SIZE, color='black'),\n",
    "            tickfont=dict(family=FONT_FAMILY, size=TICK_FONT_SIZE, color='black'),\n",
    "            range=[0, 0.018]   # x-axis range\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title='Duration',\n",
    "            titlefont=dict(family=FONT_FAMILY, size=AXIS_TITLE_FONT_SIZE, color='black'),\n",
    "            tickfont=dict(family=FONT_FAMILY, size=TICK_FONT_SIZE, color='black'),\n",
    "            range=[0, 11]     # y-axis range\n",
    "        ),\n",
    "        zaxis=dict(\n",
    "            title='F-beta',\n",
    "            titlefont=dict(family=FONT_FAMILY, size=AXIS_TITLE_FONT_SIZE, color='black'),\n",
    "            tickfont=dict(family=FONT_FAMILY, size=TICK_FONT_SIZE, color='black'),\n",
    "            range=[0.0, 1.2]  # z-axis range\n",
    "        ),\n",
    "        camera=dict(\n",
    "            eye=dict(x=1.25, y=1.25, z=1.25),\n",
    "            projection=dict(type=\"perspective\")  # Use perspective projection\n",
    "        )\n",
    "    ),\n",
    "    font=dict(family=FONT_FAMILY, size=GLOBAL_FONT_SIZE, color='black'),  # Global font settings\n",
    "    autosize=False,\n",
    "    width=1600,   # Figure width in pixels\n",
    "    height=1600,  # Figure height in pixels\n",
    "    showlegend=False  # Global setting to cancel legend\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the figure as a static image with the name \"virtual.png\"\n",
    "# fig.write_image(\"real.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bonus_factor = 1.1\n",
    "# plot F-beta score with respect to the number of iterations\n",
    "plt.plot(D[:, 2])\n",
    "plt.xlabel('Number of Iterations')\n",
    "plt.ylabel('F-beta Score')\n",
    "plt.title('F-beta Score with Respect to the Number of Iterations')\n",
    "# y starts from 0\n",
    "plt.ylim(0, bonus_factor)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track the largest F-beta score going through the iterations\n",
    "max_F_beta = np.zeros(D.shape[0])\n",
    "for i in range(D.shape[0]):\n",
    "    max_F_beta[i] = np.max(D[:i+1, 2])\n",
    "\n",
    "# plot the max_F_beta, the horizontal axis is the number of iterations, the vertical axis is the maximum F-beta score\n",
    "plt.plot(max_F_beta)\n",
    "plt.xlabel('Number of Iterations')\n",
    "plt.ylabel('Maximum F-beta Score')\n",
    "plt.title('Maximum F-beta Score vs. Number of Iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming DD is a NumPy array containing the data\n",
    "iterations = np.arange(DD.shape[0])\n",
    "precision = DD[:, -2]\n",
    "recall = DD[:, -1]\n",
    "F_beta = DD[:, 2]\n",
    "\n",
    "# Set the figure size (9x6 inches roughly corresponds to 900x600 pixels)\n",
    "plt.figure(figsize=(9, 6))\n",
    "\n",
    "# Plot each line with specified color and line width\n",
    "plt.plot(iterations, precision, label='Precision', color='blue', linewidth=1.5)\n",
    "plt.plot(iterations, recall, label='Recall', color='red', linewidth=1.5)\n",
    "plt.plot(iterations, F_beta, label='F-beta', color='green', linewidth=1.5)\n",
    "\n",
    "# Set axis labels and title, using Times New Roman font\n",
    "plt.xlabel('Number of Iterations', fontname='Times New Roman', fontsize=12)\n",
    "plt.ylabel('Value', fontname='Times New Roman', fontsize=12)\n",
    "plt.title('Precision, Recall, and F-beta Score', fontname='Times New Roman', fontsize=14)\n",
    "\n",
    "# Set y-axis limits from 0 to bonus_factor\n",
    "plt.ylim(0, bonus_factor)\n",
    "\n",
    "# Set tick labels to Times New Roman font\n",
    "plt.xticks(fontname='Times New Roman', fontsize=12)\n",
    "plt.yticks(fontname='Times New Roman', fontsize=12)\n",
    "\n",
    "# Add legend to the plot and set its font to Times New Roman\n",
    "plt.legend(prop={'family': 'Times New Roman'})\n",
    "\n",
    "# Adjust the layout to prevent clipping of labels and titles\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure as a static image file\n",
    "plt.savefig('history.png')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track the largest F-beta score going through the iterations and record associated recall and precision\n",
    "iterations = np.arange(DD.shape[0])\n",
    "max_F_beta = np.zeros(DD.shape[0])\n",
    "max_associated_recall = np.zeros(DD.shape[0])\n",
    "max_associated_precision = np.zeros(DD.shape[0])\n",
    "for i in range(DD.shape[0]):\n",
    "    max_F_beta[i] = np.max(DD[:i+1, 2])\n",
    "    max_index = np.argmax(DD[:i+1, 2])\n",
    "    max_associated_recall[i] = DD[max_index, -1]\n",
    "    max_associated_precision[i] = DD[max_index, -2]\n",
    "\n",
    "# print the max_F_beta, recall, and precision\n",
    "print(\"max f-beta, recall, precision\")\n",
    "print(max_F_beta[-1])\n",
    "print(max_associated_recall[-1])\n",
    "print(max_associated_precision[-1])\n",
    "\n",
    "# plot the max_F_beta, the horizontal axis is the number of iterations, the vertical axis is the maximum F-beta score, and associated recall and precision\n",
    "\n",
    "plt.plot(iterations, max_F_beta, label='F-beta', color='green', linewidth=1.5)\n",
    "plt.plot(iterations, max_associated_recall, label='Recall', color='red', linewidth=1.5)\n",
    "plt.plot(iterations, max_associated_precision, label='Precision', color='blue', linewidth=1.5)\n",
    "\n",
    "plt.xlabel('Number of Iterations', fontname='Times New Roman', fontsize=12)\n",
    "plt.ylabel('Value', fontname='Times New Roman', fontsize=12)\n",
    "plt.title('Maximum F-beta Score, Associated Recall, and Precision', fontname='Times New Roman', fontsize=14)\n",
    "\n",
    "# from 0 to bonus_factor\n",
    "plt.ylim(0, bonus_factor)\n",
    "\n",
    "# Set tick labels to Times New Roman font\n",
    "plt.xticks(fontname='Times New Roman', fontsize=12)\n",
    "plt.yticks(fontname='Times New Roman', fontsize=12)\n",
    "\n",
    "# legend\n",
    "plt.legend(prop={'family': 'Times New Roman'})\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
